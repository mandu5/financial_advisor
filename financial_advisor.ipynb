{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1046733,"sourceType":"datasetVersion","datasetId":578549},{"sourceId":28785,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":8318,"modelId":3301}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mandu5/financial-advisor?scriptVersionId=197124922\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install -q -U torch --index-url https://download.pytorch.org/whl/cu117\n!pip install -q -U -i https://pypi.org/simple/ bitsandbytes\n!pip install -q -U transformers\n!pip install -q -U accelerate\n!pip install -q -U datasets\n!pip install -q -U trl\n!pip install -q -U peft","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport torch\nimport pandas as pd\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nfrom datasets import Dataset\nfrom peft import LoraConfig\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/finance-data/Finance_data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_input(row):\n    profile = (\n        f\"User Profile:\\n\"\n        f\"- Gender: {row['gender']}\\n\"\n        f\"- Age: {row['age']}\\n\"\n        f\"- Investment Avenues Interested: {row['Investment_Avenues']}\\n\"\n        f\"- Preferred Investments:\\n\"\n    )\n    # List of investments with their preferences\n    investments = []\n    investment_columns = ['Mutual_Funds', 'Equity_Market', 'Debentures', 'Government_Bonds',\n                          'Fixed_Deposits', 'PPF', 'Gold']\n    for col in investment_columns:\n        preference = row[col]\n        investments.append(f\"  - {col.replace('_', ' ')} (Preference: {preference})\")\n    profile += '\\n'.join(investments) + '\\n'\n    profile += (\n        f\"- Investment Objectives: {row['Objective']}\\n\"\n        f\"- Investment Purpose: {row['Purpose']}\\n\"\n        f\"- Investment Duration: {row['Duration']}\\n\"\n        f\"- Expected Returns: {row['Expect']}\\n\"\n        f\"- Savings Objective: {row['What are your savings objectives?']}\\n\"\n        f\"- Source of Information: {row['Source']}\\n\\n\"\n        f\"Question:\\n\"\n        f\"What investment strategies should I consider?\"\n    )\n    return profile\n\ndef create_output(row):\n    # Construct an output string providing financial advice\n    output = (\n        f\"Considering your objectives of {row['Objective']} and {row['Purpose']} over {row['Duration']}, \"\n        f\"you might explore investment avenues like {row['Avenue']}. \"\n        f\"Given your expected returns of {row['Expect']}, these options align with your goals. \"\n        f\"Remember to diversify your portfolio and assess the risks involved. \"\n        f\"Consulting a financial advisor can provide personalized guidance.\"\n    )\n    return output\n\n# Create 'input' column\ndf['input'] = df.apply(create_input, axis=1)\n\n# Create 'output' column\ndf['output'] = df.apply(create_output, axis=1)\n\n# Combine 'input' and 'output' into 'text' column\ndf['text'] = df.apply(lambda row: f\"input: {row['input']}\\noutput: {row['output']}\", axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove rows with missing values\ndf.dropna(subset=['input', 'output'], inplace=True)\n\n# Shuffle the DataFrame\ndf = df.sample(frac=1).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare the text column for training\ndf['text'] = df.apply(lambda row: f\"input: {row['input']}\\noutput: {row['output']}\", axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display an example input-output pair\nexample_row = df.iloc[0]\nprint(\"Input:\")\nprint(example_row['input'])\nprint(\"\\nOutput:\")\nprint(example_row['output'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\n\n# Remove any rows with missing values in 'text'\ndf.dropna(subset=['text'], inplace=True)\n\n# Create Dataset from pandas DataFrame\ntrain_data = Dataset.from_pandas(df[['text']])\n\n# Verify the Dataset\nprint(train_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize Model\nmodel_name = \"/kaggle/input/gemma/transformers/2b-it/3\"\ncompute_dtype = getattr(torch, \"float16\")\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=False,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=compute_dtype,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    torch_dtype=compute_dtype,\n    low_cpu_mem_usage=True,\n)\n\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\nmodel.config.hidden_activation = 'gelu_pytorch_tanh'\n\nmax_seq_length = 1024\ntokenizer = AutoTokenizer.from_pretrained(model_name, max_seq_length=max_seq_length)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fine-Tune the Model\npeft_config = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=\"financial_advisor_model\",\n    num_train_epochs=3,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=8,\n    optim=\"paged_adamw_32bit\",\n    save_steps=0,\n    logging_steps=25,\n    learning_rate=5e-4,\n    weight_decay=0.001,\n    fp16=True,\n    max_grad_norm=0.3,\n    warmup_ratio=0.03,\n    lr_scheduler_type=\"cosine\",\n    report_to=\"none\",\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from trl import SFTTrainer\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_data,\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing=False,\n)\n\n# Start training\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save and Merge Model\ntrainer.save_model()\ntokenizer.save_pretrained(\"financial_advisor_model\")\n\nfrom peft import AutoPeftModelForCausalLM\n\nmodel = AutoPeftModelForCausalLM.from_pretrained(\n     \"financial_advisor_model\",\n     torch_dtype=compute_dtype,\n     device_map=\"auto\",\n)\n\nmerged_model = model.merge_and_unload()\nmerged_model.save_pretrained(\"./financial_advisor_pretrained\", safe_serialization=True, max_shard_size=\"2GB\")\ntokenizer.save_pretrained(\"./financial_advisor_pretrained\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\n\n# Specify the path to your pretrained model directory\nmodel_name = \"./financial_advisor_pretrained\"\n\n# Load the model without device_map\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n)\n\n# Move the model to GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Define a function to generate advice\ndef get_financial_advice(user_profile, model=model, tokenizer=tokenizer):\n    prompt = f\"input: {user_profile}\\noutput:\"\n    # Tokenize the input and move tensors to the same device as the model\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=150,\n        no_repeat_ngram_size=2,\n        early_stopping=True,\n    )\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return response.split('output:')[-1].strip()\n\n# Example usage\nexample_input = df.iloc[0]['input']\nprint(\"User Profile and Question:\")\nprint(example_input)\nprint(\"\\nGenerated Advice:\")\nprint(get_financial_advice(example_input))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}